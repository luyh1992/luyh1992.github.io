<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>luyh的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://luyh1992.github.io/"/>
  <updated>2017-10-30T07:53:23.688Z</updated>
  <id>http://luyh1992.github.io/</id>
  
  <author>
    <name>luyh1992</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python网络爬虫三</title>
    <link href="http://luyh1992.github.io/2017/10/24/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%89/"/>
    <id>http://luyh1992.github.io/2017/10/24/Python网络爬虫三/</id>
    <published>2017-10-24T08:05:52.000Z</published>
    <updated>2017-10-30T07:53:23.688Z</updated>
    
    <content type="html"><![CDATA[<p>根据嵩天视频教程整理</p><h1 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a>Beautiful Soup</h1><h2 id="Beautiful-Soup入门"><a href="#Beautiful-Soup入门" class="headerlink" title="Beautiful Soup入门"></a>Beautiful Soup入门</h2><h3 id="Beautiful-Soup库的基本元素"><a href="#Beautiful-Soup库的基本元素" class="headerlink" title="Beautiful Soup库的基本元素"></a>Beautiful Soup库的基本元素</h3><p>Beautiful Soup库是解析、便利、维护“标签树”的功能库。<br><a id="more"></a><br>Beautiful Soup库的引用方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div></pre></td></tr></table></figure></p><p>或者<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> bs4</div></pre></td></tr></table></figure></p><p>BeautifulSoup对应一个HTMX/XML文档的全部内容。<br>使用方式<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup</div><div class="line">soup = BeautifulSoup("&lt;html&gt;data&lt;/html&gt;", "html.parser")</div><div class="line">soup2 = BeautifulSoup(open("D://data.html"), "html.parser")</div></pre></td></tr></table></figure></p><p>Beautiful Soup库解析器<br>|解析器|使用方法|条件|<br>|-|-|-|<br>|bs4的HTML解析器|BeautifulSoup(mk,”html.parser”)|安装bs4库|<br>|lxml的HTML解析器|BeautifulSoup(mk,”lxml”)|pip install lxml|<br>|lxml的XML解析器|BeautifulSoup(mk,”xml”)|pip install lxml|<br>|html5lib的解析器|BeautifulSoup(mk,”html5lib”)|pip install html5lib|<br>Beautiful Soup类的基本元素<br>|基本元素|说明|<br>|-|-|<br>|Tag|标签，最基本测信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾|<br>|Name|标签的名字，格式：tag.name|<br>|Attributes|标签的属性，字典形式组织，格式：tag.attrs|<br>|NavigableString|标签内非属性字符串，格式：tag.string|<br>|Comment|标签内字符串的注释部分，一种特殊的Comment类型|</p><h3 id="基于bs4库的HTML内容遍历方法"><a href="#基于bs4库的HTML内容遍历方法" class="headerlink" title="基于bs4库的HTML内容遍历方法"></a>基于bs4库的HTML内容遍历方法</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据嵩天视频教程整理&lt;/p&gt;
&lt;h1 id=&quot;Beautiful-Soup&quot;&gt;&lt;a href=&quot;#Beautiful-Soup&quot; class=&quot;headerlink&quot; title=&quot;Beautiful Soup&quot;&gt;&lt;/a&gt;Beautiful Soup&lt;/h1&gt;&lt;h2 id=&quot;Beautiful-Soup入门&quot;&gt;&lt;a href=&quot;#Beautiful-Soup入门&quot; class=&quot;headerlink&quot; title=&quot;Beautiful Soup入门&quot;&gt;&lt;/a&gt;Beautiful Soup入门&lt;/h2&gt;&lt;h3 id=&quot;Beautiful-Soup库的基本元素&quot;&gt;&lt;a href=&quot;#Beautiful-Soup库的基本元素&quot; class=&quot;headerlink&quot; title=&quot;Beautiful Soup库的基本元素&quot;&gt;&lt;/a&gt;Beautiful Soup库的基本元素&lt;/h3&gt;&lt;p&gt;Beautiful Soup库是解析、便利、维护“标签树”的功能库。&lt;br&gt;
    
    </summary>
    
      <category term="Python" scheme="http://luyh1992.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://luyh1992.github.io/tags/Python/"/>
    
      <category term="爬虫" scheme="http://luyh1992.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python网络爬虫二</title>
    <link href="http://luyh1992.github.io/2017/10/24/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%BA%8C/"/>
    <id>http://luyh1992.github.io/2017/10/24/Python网络爬虫二/</id>
    <published>2017-10-24T06:43:41.000Z</published>
    <updated>2017-10-24T07:24:12.188Z</updated>
    
    <content type="html"><![CDATA[<p>根据嵩天视频教程整理</p><h1 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h1><h2 id="网络爬虫引发的问题"><a href="#网络爬虫引发的问题" class="headerlink" title="网络爬虫引发的问题"></a>网络爬虫引发的问题</h2><p>网络爬虫按尺寸可以划分为三大类：<br>&emsp;&emsp;爬取网页：小规模，数据量小，爬取速度不敏感。使用Request库实现<br>&emsp;&emsp;爬取网站，爬取系列网站：中规模，数据规模较大，爬取速度敏感。Scrapy库实现<br>&emsp;&emsp;爬取全网：大规模，搜索引擎，爬去速度关键。需要定制开发  </p><a id="more"></a><p>受限于编程水平和目的，网络爬虫将会给web服务器带来巨大的资源开销。<br>由于服务器上的数据往往具有产权归属，网络爬虫获得数据后用于牟利将带来法律风险。<br>网络爬虫可能具备突破简单访问控制的能力，获得被保护数据从而泄露个人隐私。  </p><h2 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a>网络爬虫的限制</h2><p>来源审查：判断User-Agent进行限制<br>&emsp;&emsp;检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问。<br>发布公告：Robots协议<br>&emsp;&emsp;告知所有爬虫网站的爬取策略，要求爬虫遵守。  </p><h2 id="Robots协议-1"><a href="#Robots协议-1" class="headerlink" title="Robots协议"></a>Robots协议</h2><p>Robots协议全称Robots Exclusion Standard，即为网络爬虫排除标准。其作用是告知网络爬虫哪些内容可以抓取，哪些不能。<br>Robots协议通过在根目录给定robots.txt文件来实现上述功能。<br>案例：京东的Robots协议<br><a href="https://www.jd.com/robots.txt" target="_blank" rel="external">https://www.jd.com/robots.txt</a><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">User-agent: *</div><div class="line">Disallow: /?*</div><div class="line">Disallow: /pop/*.html</div><div class="line">Disallow: /pinpai/*.html?*</div><div class="line">User-agent: EtaoSpider</div><div class="line">Disallow: /</div><div class="line">User-agent: HuihuiSpider</div><div class="line">Disallow: /</div><div class="line">User-agent: GwdangSpider</div><div class="line">Disallow: /</div><div class="line">User-agent: WochachaSpider</div><div class="line">Disallow: /</div></pre></td></tr></table></figure></p><h2 id="Robots协议的使用"><a href="#Robots协议的使用" class="headerlink" title="Robots协议的使用"></a>Robots协议的使用</h2><p>对于任何网络爬虫，都应该能自动或者人工地识别robots.txt文件，再进行内容爬取。但Robots协议是建议而非约束性，网络爬虫可以不遵守，但存在法律风险。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据嵩天视频教程整理&lt;/p&gt;
&lt;h1 id=&quot;Robots协议&quot;&gt;&lt;a href=&quot;#Robots协议&quot; class=&quot;headerlink&quot; title=&quot;Robots协议&quot;&gt;&lt;/a&gt;Robots协议&lt;/h1&gt;&lt;h2 id=&quot;网络爬虫引发的问题&quot;&gt;&lt;a href=&quot;#网络爬虫引发的问题&quot; class=&quot;headerlink&quot; title=&quot;网络爬虫引发的问题&quot;&gt;&lt;/a&gt;网络爬虫引发的问题&lt;/h2&gt;&lt;p&gt;网络爬虫按尺寸可以划分为三大类：&lt;br&gt;&amp;emsp;&amp;emsp;爬取网页：小规模，数据量小，爬取速度不敏感。使用Request库实现&lt;br&gt;&amp;emsp;&amp;emsp;爬取网站，爬取系列网站：中规模，数据规模较大，爬取速度敏感。Scrapy库实现&lt;br&gt;&amp;emsp;&amp;emsp;爬取全网：大规模，搜索引擎，爬去速度关键。需要定制开发  &lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://luyh1992.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://luyh1992.github.io/tags/Python/"/>
    
      <category term="爬虫" scheme="http://luyh1992.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python网络爬虫 一</title>
    <link href="http://luyh1992.github.io/2017/10/23/Pytthon%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"/>
    <id>http://luyh1992.github.io/2017/10/23/Pytthon网络爬虫/</id>
    <published>2017-10-23T07:17:51.000Z</published>
    <updated>2017-10-24T07:24:06.738Z</updated>
    
    <content type="html"><![CDATA[<p>根据嵩天视频教程整理</p><h1 id="Request库"><a href="#Request库" class="headerlink" title="Request库"></a>Request库</h1><h2 id="Request库安装"><a href="#Request库安装" class="headerlink" title="Request库安装"></a>Request库安装</h2><p>在命令行执行代码安装requests库<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install requests</div></pre></td></tr></table></figure></p><a id="more"></a><p>测试安装效果<br>在IDLE中执行下列代码<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">r = requests.get("http://www.baidu.com")</div><div class="line">r.status_code</div><div class="line">r.encoding = "utf-8"</div><div class="line">r.text</div></pre></td></tr></table></figure></p><p>可以爬取到百度首页的内容</p><h2 id="Request库的主要方法"><a href="#Request库的主要方法" class="headerlink" title="Request库的主要方法"></a>Request库的主要方法</h2><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>requests.request()</td><td>构造一个请求，支撑以下各方法的基本方法</td></tr><tr><td>requests.get()</td><td>获取HTML网页的主要方法</td></tr><tr><td>requests.head()</td><td>获取HTTP网页头信息的方法</td></tr><tr><td>requests.post()</td><td>向HTML网页提交POST请求的方法</td></tr><tr><td>requests.put()</td><td>向HTML网页提交PUT请求的方法</td></tr><tr><td>requests.patch()</td><td>向HTML网页提交局部修改请求</td></tr><tr><td>requests.delete()</td><td>向HTML网页提交删除请求</td></tr></tbody></table><p>其中常用方法为get()和head()。</p><h3 id="request-方法"><a href="#request-方法" class="headerlink" title="request()方法"></a>request()方法</h3><p>request()方法为基本方法，其它方法都是通过request()方法实现。<br>request()方法的参数列表如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">requests.request(method, url, **kwargs)</div></pre></td></tr></table></figure></p><p>method表示请求方法；<br>url表示所要访问的路径<br>**kwargs表示13个控制访问的参数，为可选项，包括：<br>&emsp;&emsp;params：字典或字节序列，作为参数增加到url中<br>&emsp;&emsp;data：字典、字节序列或文件对象，作为Request的内容<br>&emsp;&emsp;json：JSON格式的数据，作为Request的内容<br>&emsp;&emsp;headers：字典，HTTP定制头<br>&emsp;&emsp;cookies：字典或CookieJar，Request中的cookie<br>&emsp;&emsp;auth：元组，支持HTTP认证功能<br>&emsp;&emsp;files：字典类型，传输文件<br>&emsp;&emsp;timeout：设定超时时间，单位为秒<br>&emsp;&emsp;proxies：字典类型，设置访问代理服务器<br>&emsp;&emsp;allow_redirects：重定向开关，默认为True<br>&emsp;&emsp;stream：获取内容立即下载开关，默认为True<br>&emsp;&emsp;verify：认证SSL证书开关，默认为True<br>&emsp;&emsp;cert：本地SSL证书路径  </p><p>params参数使用方法如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">kv = &#123;'key1':'value1', 'key2':'value2'&#125;</div><div class="line">r = requests.request('GET', 'http://python123.io/ws', params=kv)</div><div class="line">print(r.url)</div></pre></td></tr></table></figure></p><p>其输出结果为：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://python123.io/ws?key1=value1&amp;key2=value2</div></pre></td></tr></table></figure></p><h3 id="get-方法"><a href="#get-方法" class="headerlink" title="get()方法"></a>get()方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">r = requests.get(url, params=<span class="keyword">None</span>, **kwargs)</div></pre></td></tr></table></figure><p>此方法通过get和url构造一个向服务器请求资源的Request对象，同时返回一个包含服务器资源的Response对象。</p><p>Response对象的属性如下：  </p><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>r.status_code</td><td>HTTP请求的返回状态，200表示连接成功，404表示失败</td></tr><tr><td>r.text</td><td>HTTP响应内容的字符串形式</td></tr><tr><td>r.encoding</td><td>从HTTP header中猜测的响应内容编码方式，如果在header中不存在charset，则认为编码为ISO-8859-1</td></tr><tr><td>r.apparent_encoding</td><td>从内容中分析出的响应内容编码方式</td></tr><tr><td>r.content</td><td>HTTP响应内容的二进制形式</td></tr></tbody></table><h2 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h2><h3 id="Requests库的异常"><a href="#Requests库的异常" class="headerlink" title="Requests库的异常"></a>Requests库的异常</h3><table><thead><tr><th>异常</th><th>说明</th></tr></thead><tbody><tr><td>requests.ConnectionError</td><td>网络连接错误异常，如DNS查询失败、拒绝连接等</td></tr><tr><td>requests.HTTPError</td><td>HTTP错误异常</td></tr><tr><td>requests.URLRequired</td><td>URL缺失异常</td></tr><tr><td>requests.TooManyRedirects</td><td>超过最大重定向次数，产生重定向异常</td></tr><tr><td>requests.ConnectTimeout</td><td>连接远程服务器超时异常</td></tr><tr><td>requests.Timeout</td><td>请求URL超时</td></tr></tbody></table><p>Response对象提供异常处理方法raise_for_status()。该方法判断返回类型是否是200，如果是200，表示返回内容正确，如果不是200，产生requests.HTTPError异常。</p><h3 id="通用代码框架"><a href="#通用代码框架" class="headerlink" title="通用代码框架"></a>通用代码框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        r = requests.get(url)</div><div class="line">        r.raise_for_status()</div><div class="line">        r.encoding = r.apparent_encoding</div><div class="line">        <span class="keyword">return</span> r.text</div><div class="line">    <span class="keyword">except</span>:</div><div class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    url = <span class="string">"http://www.baidu.com"</span></div><div class="line">    print(getHTMLText(url))</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据嵩天视频教程整理&lt;/p&gt;
&lt;h1 id=&quot;Request库&quot;&gt;&lt;a href=&quot;#Request库&quot; class=&quot;headerlink&quot; title=&quot;Request库&quot;&gt;&lt;/a&gt;Request库&lt;/h1&gt;&lt;h2 id=&quot;Request库安装&quot;&gt;&lt;a href=&quot;#Request库安装&quot; class=&quot;headerlink&quot; title=&quot;Request库安装&quot;&gt;&lt;/a&gt;Request库安装&lt;/h2&gt;&lt;p&gt;在命令行执行代码安装requests库&lt;br&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;pip install requests&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://luyh1992.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://luyh1992.github.io/tags/Python/"/>
    
      <category term="爬虫" scheme="http://luyh1992.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://luyh1992.github.io/2017/10/20/hello-world/"/>
    <id>http://luyh1992.github.io/2017/10/20/hello-world/</id>
    <published>2017-10-20T08:52:58.263Z</published>
    <updated>2017-10-23T08:54:09.920Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p><a id="more"></a><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Writing&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
