<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Python网络爬虫三]]></title>
      <url>/2017/10/24/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%89/</url>
      <content type="html"><![CDATA[<p>根据嵩天视频教程整理</p>
<h1 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a>Beautiful Soup</h1><h2 id="Beautiful-Soup入门"><a href="#Beautiful-Soup入门" class="headerlink" title="Beautiful Soup入门"></a>Beautiful Soup入门</h2><h3 id="Beautiful-Soup库的基本元素"><a href="#Beautiful-Soup库的基本元素" class="headerlink" title="Beautiful Soup库的基本元素"></a>Beautiful Soup库的基本元素</h3><p>Beautiful Soup库是解析、便利、维护“标签树”的功能库。<br><a id="more"></a><br>Beautiful Soup库的引用方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div></pre></td></tr></table></figure></p>
<p>或者<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> bs4</div></pre></td></tr></table></figure></p>
<p>BeautifulSoup对应一个HTMX/XML文档的全部内容。<br>使用方式<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup</div><div class="line">soup = BeautifulSoup("&lt;html&gt;data&lt;/html&gt;", "html.parser")</div><div class="line">soup2 = BeautifulSoup(open("D://data.html"), "html.parser")</div></pre></td></tr></table></figure></p>
<p>Beautiful Soup库解析器<br>|解析器|使用方法|条件|<br>|-|-|-|<br>|bs4的HTML解析器|BeautifulSoup(mk,”html.parser”)|安装bs4库|<br>|lxml的HTML解析器|BeautifulSoup(mk,”lxml”)|pip install lxml|<br>|lxml的XML解析器|BeautifulSoup(mk,”xml”)|pip install lxml|<br>|html5lib的解析器|BeautifulSoup(mk,”html5lib”)|pip install html5lib|<br>Beautiful Soup类的基本元素<br>|基本元素|说明|<br>|-|-|<br>|Tag|标签，最基本测信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾|<br>|Name|标签的名字，格式：<tag>.name|<br>|Attributes|标签的属性，字典形式组织，格式：<tag>.attrs|<br>|NavigableString|标签内非属性字符串，格式：<tag>.string|<br>|Comment|标签内字符串的注释部分，一种特殊的Comment类型|</tag></tag></tag></p>
<h3 id="基于bs4库的HTML内容遍历方法"><a href="#基于bs4库的HTML内容遍历方法" class="headerlink" title="基于bs4库的HTML内容遍历方法"></a>基于bs4库的HTML内容遍历方法</h3>]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python网络爬虫二]]></title>
      <url>/2017/10/24/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%BA%8C/</url>
      <content type="html"><![CDATA[<p>根据嵩天视频教程整理</p>
<h1 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h1><h2 id="网络爬虫引发的问题"><a href="#网络爬虫引发的问题" class="headerlink" title="网络爬虫引发的问题"></a>网络爬虫引发的问题</h2><p>网络爬虫按尺寸可以划分为三大类：<br>&emsp;&emsp;爬取网页：小规模，数据量小，爬取速度不敏感。使用Request库实现<br>&emsp;&emsp;爬取网站，爬取系列网站：中规模，数据规模较大，爬取速度敏感。Scrapy库实现<br>&emsp;&emsp;爬取全网：大规模，搜索引擎，爬去速度关键。需要定制开发  </p>
<a id="more"></a>
<p>受限于编程水平和目的，网络爬虫将会给web服务器带来巨大的资源开销。<br>由于服务器上的数据往往具有产权归属，网络爬虫获得数据后用于牟利将带来法律风险。<br>网络爬虫可能具备突破简单访问控制的能力，获得被保护数据从而泄露个人隐私。  </p>
<h2 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a>网络爬虫的限制</h2><p>来源审查：判断User-Agent进行限制<br>&emsp;&emsp;检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问。<br>发布公告：Robots协议<br>&emsp;&emsp;告知所有爬虫网站的爬取策略，要求爬虫遵守。  </p>
<h2 id="Robots协议-1"><a href="#Robots协议-1" class="headerlink" title="Robots协议"></a>Robots协议</h2><p>Robots协议全称Robots Exclusion Standard，即为网络爬虫排除标准。其作用是告知网络爬虫哪些内容可以抓取，哪些不能。<br>Robots协议通过在根目录给定robots.txt文件来实现上述功能。<br>案例：京东的Robots协议<br><a href="https://www.jd.com/robots.txt" target="_blank" rel="external">https://www.jd.com/robots.txt</a><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">User-agent: *</div><div class="line">Disallow: /?*</div><div class="line">Disallow: /pop/*.html</div><div class="line">Disallow: /pinpai/*.html?*</div><div class="line">User-agent: EtaoSpider</div><div class="line">Disallow: /</div><div class="line">User-agent: HuihuiSpider</div><div class="line">Disallow: /</div><div class="line">User-agent: GwdangSpider</div><div class="line">Disallow: /</div><div class="line">User-agent: WochachaSpider</div><div class="line">Disallow: /</div></pre></td></tr></table></figure></p>
<h2 id="Robots协议的使用"><a href="#Robots协议的使用" class="headerlink" title="Robots协议的使用"></a>Robots协议的使用</h2><p>对于任何网络爬虫，都应该能自动或者人工地识别robots.txt文件，再进行内容爬取。但Robots协议是建议而非约束性，网络爬虫可以不遵守，但存在法律风险。</p>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python网络爬虫 一]]></title>
      <url>/2017/10/23/Pytthon%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/</url>
      <content type="html"><![CDATA[<p>根据嵩天视频教程整理</p>
<h1 id="Request库"><a href="#Request库" class="headerlink" title="Request库"></a>Request库</h1><h2 id="Request库安装"><a href="#Request库安装" class="headerlink" title="Request库安装"></a>Request库安装</h2><p>在命令行执行代码安装requests库<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install requests</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>测试安装效果<br>在IDLE中执行下列代码<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">r = requests.get("http://www.baidu.com")</div><div class="line">r.status_code</div><div class="line">r.encoding = "utf-8"</div><div class="line">r.text</div></pre></td></tr></table></figure></p>
<p>可以爬取到百度首页的内容</p>
<h2 id="Request库的主要方法"><a href="#Request库的主要方法" class="headerlink" title="Request库的主要方法"></a>Request库的主要方法</h2><table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests.request()</td>
<td>构造一个请求，支撑以下各方法的基本方法</td>
</tr>
<tr>
<td>requests.get()</td>
<td>获取HTML网页的主要方法</td>
</tr>
<tr>
<td>requests.head()</td>
<td>获取HTTP网页头信息的方法</td>
</tr>
<tr>
<td>requests.post()</td>
<td>向HTML网页提交POST请求的方法</td>
</tr>
<tr>
<td>requests.put()</td>
<td>向HTML网页提交PUT请求的方法</td>
</tr>
<tr>
<td>requests.patch()</td>
<td>向HTML网页提交局部修改请求</td>
</tr>
<tr>
<td>requests.delete()</td>
<td>向HTML网页提交删除请求</td>
</tr>
</tbody>
</table>
<p>其中常用方法为get()和head()。</p>
<h3 id="request-方法"><a href="#request-方法" class="headerlink" title="request()方法"></a>request()方法</h3><p>request()方法为基本方法，其它方法都是通过request()方法实现。<br>request()方法的参数列表如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">requests.request(method, url, **kwargs)</div></pre></td></tr></table></figure></p>
<p>method表示请求方法；<br>url表示所要访问的路径<br>**kwargs表示13个控制访问的参数，为可选项，包括：<br>&emsp;&emsp;params：字典或字节序列，作为参数增加到url中<br>&emsp;&emsp;data：字典、字节序列或文件对象，作为Request的内容<br>&emsp;&emsp;json：JSON格式的数据，作为Request的内容<br>&emsp;&emsp;headers：字典，HTTP定制头<br>&emsp;&emsp;cookies：字典或CookieJar，Request中的cookie<br>&emsp;&emsp;auth：元组，支持HTTP认证功能<br>&emsp;&emsp;files：字典类型，传输文件<br>&emsp;&emsp;timeout：设定超时时间，单位为秒<br>&emsp;&emsp;proxies：字典类型，设置访问代理服务器<br>&emsp;&emsp;allow_redirects：重定向开关，默认为True<br>&emsp;&emsp;stream：获取内容立即下载开关，默认为True<br>&emsp;&emsp;verify：认证SSL证书开关，默认为True<br>&emsp;&emsp;cert：本地SSL证书路径  </p>
<p>params参数使用方法如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">kv = &#123;'key1':'value1', 'key2':'value2'&#125;</div><div class="line">r = requests.request('GET', 'http://python123.io/ws', params=kv)</div><div class="line">print(r.url)</div></pre></td></tr></table></figure></p>
<p>其输出结果为：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://python123.io/ws?key1=value1&amp;key2=value2</div></pre></td></tr></table></figure></p>
<h3 id="get-方法"><a href="#get-方法" class="headerlink" title="get()方法"></a>get()方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">r = requests.get(url, params=<span class="keyword">None</span>, **kwargs)</div></pre></td></tr></table></figure>
<p>此方法通过get和url构造一个向服务器请求资源的Request对象，同时返回一个包含服务器资源的Response对象。</p>
<p>Response对象的属性如下：  </p>
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>r.status_code</td>
<td>HTTP请求的返回状态，200表示连接成功，404表示失败</td>
</tr>
<tr>
<td>r.text</td>
<td>HTTP响应内容的字符串形式</td>
</tr>
<tr>
<td>r.encoding</td>
<td>从HTTP header中猜测的响应内容编码方式，如果在header中不存在charset，则认为编码为ISO-8859-1</td>
</tr>
<tr>
<td>r.apparent_encoding</td>
<td>从内容中分析出的响应内容编码方式</td>
</tr>
<tr>
<td>r.content</td>
<td>HTTP响应内容的二进制形式</td>
</tr>
</tbody>
</table>
<h2 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h2><h3 id="Requests库的异常"><a href="#Requests库的异常" class="headerlink" title="Requests库的异常"></a>Requests库的异常</h3><table>
<thead>
<tr>
<th>异常</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests.ConnectionError</td>
<td>网络连接错误异常，如DNS查询失败、拒绝连接等</td>
</tr>
<tr>
<td>requests.HTTPError</td>
<td>HTTP错误异常</td>
</tr>
<tr>
<td>requests.URLRequired</td>
<td>URL缺失异常</td>
</tr>
<tr>
<td>requests.TooManyRedirects</td>
<td>超过最大重定向次数，产生重定向异常</td>
</tr>
<tr>
<td>requests.ConnectTimeout</td>
<td>连接远程服务器超时异常</td>
</tr>
<tr>
<td>requests.Timeout</td>
<td>请求URL超时</td>
</tr>
</tbody>
</table>
<p>Response对象提供异常处理方法raise_for_status()。该方法判断返回类型是否是200，如果是200，表示返回内容正确，如果不是200，产生requests.HTTPError异常。</p>
<h3 id="通用代码框架"><a href="#通用代码框架" class="headerlink" title="通用代码框架"></a>通用代码框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        r = requests.get(url)</div><div class="line">        r.raise_for_status()</div><div class="line">        r.encoding = r.apparent_encoding</div><div class="line">        <span class="keyword">return</span> r.text</div><div class="line">    <span class="keyword">except</span>:</div><div class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    url = <span class="string">"http://www.baidu.com"</span></div><div class="line">    print(getHTMLText(url))</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2017/10/20/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<a id="more"></a>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        
    </entry>
    
  
  
</search>
